{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "email processing system\n",
    "\n",
    "Read incoming emails\n",
    "Classify them as spam or legitimate\n",
    "Draft a preliminary response for legitimate emails\n",
    "Send information to Mr. Wayne when legitimate (printing only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "    \n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "    \n",
    "    # Response generation\n",
    "    draft_response: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis\n",
    "\n",
    "    spam_reason: Optional[str]  # Reason for marking as spam\n",
    "\n",
    "    email_category: Optional[str] = \"general\"  # Category of email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat_ollama = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our LLM\n",
    "model = chat_ollama\n",
    "\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, analyze this email and determine if it is spam or legitimate.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    First, determine if this email is spam. If it is spam, explain why.\n",
    "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    response_text = response.content.lower()\n",
    "    is_spam = \" spam \" in response_text and \" not spam \" not in response_text\n",
    "    \n",
    "    # Extract a reason if it's spam\n",
    "    spam_reason = None\n",
    "    if is_spam and \"reason:\" in response_text:\n",
    "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
    "    \n",
    "    # Determine category if legitimate\n",
    "    email_category = None\n",
    "    if not is_spam:\n",
    "        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]\n",
    "        for category in categories:\n",
    "            if category in response_text:\n",
    "                email_category = category\n",
    "                break\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    \n",
    "    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason'] or 'unknown'}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_email_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    category = state[\"email_category\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"draft_response\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_hugg(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Category: {state['email_category']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)\n",
    "email_graph.add_node(\"classify_email\", classify_email)\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)\n",
    "email_graph.add_node(\"draft_email_response\", draft_email_response)\n",
    "email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)\n",
    "\n",
    "email_graph.add_edge(START, \"read_email\")\n",
    "\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",\n",
    "        \"legitimate\": \"draft_email_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "\n",
    "email_graph.add_edge(\"handle_spam\", END)\n",
    "email_graph.add_edge(\"draft_email_response\", \"notify_mr_hugg\")\n",
    "email_graph.add_edge(\"notify_mr_hugg\", END)\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}\n",
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process the spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-788d9fde-d2d9-4c62-af14-bff973380a88\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-93f1d1e6-4714-4d1f-bdb3-cbbb4077eae3\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from john.smith@example.com.\n",
      "Subject: Question about your services\n",
      "Category: inquiry\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Here's a polite preliminary response from Alfred the butler:\n",
      "\n",
      "\"Dear Mr. Hugg,\n",
      "\n",
      "I am delighted to receive your inquiry regarding our consulting services. I would be more than happy to schedule a call with you at your earliest convenience.\n",
      "\n",
      "Please let me know a suitable time and date for us to discuss further, and I shall ensure that it is arranged accordingly.\n",
      "\n",
      "Thank you for considering our company for your needs.\n",
      "\n",
      "Best regards,\n",
      "Alfred\"\n",
      "\n",
      "This response acknowledges the sender's inquiry, expresses enthusiasm for discussing their services, and provides an opportunity for Mr. Hugg to respond with a specific time and date.\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Process legitimate email\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\"email\": legitimate_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_graph.get_graph().draw_mermaid_png()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
